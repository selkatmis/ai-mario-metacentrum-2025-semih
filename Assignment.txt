Homework
Do two Super Mario experiments using MetaCentrum. The first is the same for everyone,
the second one is up to your choice – either from a list of my ideas, or try to come up with
something yourself.
Common task
Everyone does this.
Agent: astar
Parameters: searchSteps, timeToFinish weight
Values: searchSteps: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20)
timeToFinish weight: (0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0)
all combinations = 11 * 10 parameter sets total
Levels: 15 original levels + first 15 krys levels + first 15 patternCount levels
Metrics: everything AgentBenchmarkGame.runGame returns
+ mostBacktrackedNodes (got through IAgentBenchmarkBacktrack interface)
Visualization: at least two 2D plots (heatmaps) showing the dependence of win rate and run

time on both of the parameters

Elective task
Choose one.
Required complexity
1) At least two parameter combinations (it’s ok to use one new parameter and combine
it with some that has already been tested, if there is no other new parameter that
could be used).
2) At least 100 parameter combinations.
3) Test at all 15 original levels, the first 100 krys and at least 100 other levels (it should
be almost no extra work testing it on the first 100 levels of each level pack). Notice
that you are using a different set of levels for this task compared to the
common task.
4) All of the metrics as in the Common task.
5) Visualization: probably something similar to the Common task, tailor it so that
conclusions can be drawn about the effects of the changes that you did, the most
interesting stuff is win rate, run time and nodes evaluated.
6) The content to be submitted is described in the Submission section.
7) The number of students to do each experiment is limited, you need to validate
your choice with me and get into the table first! To do so, contact me on
Discord.

Ideas
astarWindow
1. Try different values of rightWindowBorderX (the size of the window).
astarWaypoints
0. Be warned that this agent has not been perfectly validated and tuned on “standard”
levels.
1. WAYPOINT_DENSITY, WAYPOINT_HORIZONTAL_DISTANCE_TOLERANCE,
WAYPOINT_VERTICAL_DISTANCE_TOLERANCE
a. possibly in combination with astarGrid parameters

any agent (astar, astarGrid)
1. Try more complex node cost calculations.
a. “Square something.”
b. i.e. use polynomials of degree 2 somewhere in the calculation
c. e.g. TTF^2 + TTF + ND^2 + ND
d. similarly with astarGrid params
e. be careful about combinatorial explosion
2. Give the agent more/less time to think.
a. Try a range of values from way less to way more.
b. Including the current value to allow for comparison.
3. Include verticality in node cost calculation.
a. e.g. prefer higher positions, but definitely try more options
4. Try dynamic weighting.
a. Basically decrease/increase the heuristic weight as you near the goal.
i. Try both, possibly in some more complex way.
b. https://stackoverflow.com/questions/44274729/a-search-advantages-of-dyna
mic-weighting

5. Test it on some new level pack (not present in the framework).
a. e.g. https://arxiv.org/pdf/1603.00930.pdf, but this unfortunately does not
provide level source files
i. feel free to write the paper authors and ask them for the files
b. any interesting level pack that you can find, but please no simple levels
i. e.g. Infinite Mario levels are too simple
(https://www.youtube.com/watch?v=tJHLxDoyigo)

c. Talk to me when you find something before getting to work, as we will need to
figure out which agent and parameters to use.

6. Make the agent perform specific events during the level (e.g., killing an enemy,
collecting a coin) by changing the heuristic. Try to still keep the agent capable of
finishing levels. Report number of events occurred and won levels depending on the
weight of the priority for the event.
Additional info
Do not test what has already been tested.
● nodeDepth + timeToFinish for astar
● nodeDepth + timeToFinish + DFPT + DFPAP + DFPMP for astarGrid
The repository (to fork) – Example MetaCentrum scripts

Use the following line in your PBS settings:
#PBS -l select=1:ncpus=1:mem=4gb:scratch_local=1gb:cluster=TODO
to ensure that we get somewhat consistent results (line already part of example scripts).
Replace the TODO with a cluster that is currently available (find one on
metavo.metacentrum.cz -> Current state -> Physical machines).
Deadline
A friendly tip: Do not leave the homework for the last day or two.
Deadline: 6.11.2025 (end of day CEST)
Deadline for asking to postpone: 3.11.2025 (end of day CEST)
Submission
Submit a link to a public GitLab/GitHub repository with all of the following to
sosvald@ksvi.mff.cuni.cz (ideal case is forking the repo):
1) The whole project with all of your changes committed (no autogenerated binaries
etc.!).
2) Your MetaCentrum scripts.
3) The results that you get from running your tests (files with parameter values and
metrics, e.g. in the CSV format that I use).
4) A text description (.txt file) describing what you tested, with what values, and what did
you visualize + a short report about the results that you got and your explanation for
the results.
5) Graphs showing the results. The graphs should have a name and axes descriptions.
Evaluation
Either done or not. If not, I will return it to you with instructions and advice and give you a bit
more time.